{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f39fe39",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'xopen' from 'datasets.utils.file_utils' (C:\\Users\\world\\AppData\\Roaming\\Python\\Python312\\site-packages\\datasets\\utils\\file_utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\datasets\\__init__.py:17\u001b[0m\n\u001b[0;32m      1\u001b[0m # flake8: noqa\n\u001b[0;32m      2\u001b[0m # Copyright 2020 The HuggingFace Datasets Authors and the TensorFlow Datasets Authors.\n\u001b[0;32m      3\u001b[0m #\n\u001b[0;32m      4\u001b[0m # Licensed under the Apache License, Version 2.0 (the \"License\");\n\u001b[0;32m      5\u001b[0m # you may not use this file except in compliance with the License.\n\u001b[0;32m      6\u001b[0m # You may obtain a copy of the License at\n\u001b[0;32m      7\u001b[0m #\n\u001b[0;32m      8\u001b[0m #     http://www.apache.org/licenses/LICENSE-2.0\n\u001b[0;32m      9\u001b[0m #\n\u001b[0;32m     10\u001b[0m # Unless required by applicable law or agreed to in writing, software\n\u001b[0;32m     11\u001b[0m # distributed under the License is distributed on an \"AS IS\" BASIS,\n\u001b[0;32m     12\u001b[0m # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\u001b[0;32m     13\u001b[0m # See the License for the specific language governing permissions and\n\u001b[0;32m     14\u001b[0m # limitations under the License.\n\u001b[0;32m     15\u001b[0m \n\u001b[0;32m     16\u001b[0m # Lint as: python3\n\u001b[1;32m---> 17\u001b[0m # pylint: enable=line-too-long\n\u001b[0;32m     18\u001b[0m # pylint: disable=g-import-not-at-top,g-bad-import-order,wrong-import-position\n\u001b[0;32m     20\u001b[0m __version__ = \"2.13.0\"\n\u001b[0;32m     22\u001b[0m import platform\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\datasets\\arrow_dataset.py:78\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeatures\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Audio, ClassLabel, Features, Image, Sequence, Value\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeatures\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeatures\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     71\u001b[0m     FeatureType,\n\u001b[0;32m     72\u001b[0m     _align_features,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     76\u001b[0m     require_decoding,\n\u001b[0;32m     77\u001b[0m )\n\u001b[1;32m---> 78\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfilesystems\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m extract_path_from_uri, is_remote_filesystem\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfingerprint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     80\u001b[0m     fingerprint_transform,\n\u001b[0;32m     81\u001b[0m     format_kwargs_for_fingerprint,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     89\u001b[0m     validate_fingerprint,\n\u001b[0;32m     90\u001b[0m )\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformatting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m format_table, get_format_type_from_alias, get_formatter, query_table\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\datasets\\arrow_writer.py:28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeatures\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Features, Image, Value\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeatures\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeatures\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     29\u001b[0m     FeatureType,\n\u001b[0;32m     30\u001b[0m     _ArrayXDExtensionType,\n\u001b[0;32m     31\u001b[0m     cast_to_python_objects,\n\u001b[0;32m     32\u001b[0m     generate_from_arrow_type,\n\u001b[0;32m     33\u001b[0m     get_nested_type,\n\u001b[0;32m     34\u001b[0m     list_of_np_array_to_pyarrow_listarray,\n\u001b[0;32m     35\u001b[0m     numpy_to_pyarrow_listarray,\n\u001b[0;32m     36\u001b[0m     to_pyarrow_listarray,\n\u001b[0;32m     37\u001b[0m )\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfilesystems\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_remote_filesystem\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DatasetInfo\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\datasets\\features\\__init__.py:21\u001b[0m\n\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\datasets\\features\\features.py:45\u001b[0m\n\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\datasets\\features\\nifti.py:12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DownloadConfig\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtable\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array_cast\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_local_path, xopen\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpy_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m string_to_dict\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'xopen' from 'datasets.utils.file_utils' (C:\\Users\\world\\AppData\\Roaming\\Python\\Python312\\site-packages\\datasets\\utils\\file_utils.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "import random\n",
    "\n",
    "def prepare_wtq_subset(sample_size=50):\n",
    "    print(f\">>> 正在从 Hugging Face 加载 WikiTableQuestions 数据集...\")\n",
    "    \n",
    "    # 1. 加载数据集 (只加载测试集)\n",
    "    # 这可能会花一点时间下载，取决于网速\n",
    "    dataset = load_dataset(\"wikitablequestions\", split=\"test\")\n",
    "    \n",
    "    print(f\"    原始测试集大小: {len(dataset)} 条\")\n",
    "    \n",
    "    # 2. 随机采样\n",
    "    # 为了保证实验可复现，设置随机种子\n",
    "    random.seed(42)\n",
    "    indices = random.sample(range(len(dataset)), sample_size)\n",
    "    \n",
    "    sampled_data = dataset.select(indices)\n",
    "    \n",
    "    output_dir = \"benchmark_real\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "    tasks = []\n",
    "    \n",
    "    print(f\">>> 正在处理 {sample_size} 条样本，生成 CSV...\")\n",
    "    \n",
    "    for i, item in enumerate(sampled_data):\n",
    "        # WTQ 的数据结构: {'table': {'header': [...], 'rows': [...]}, 'question': '...'}\n",
    "        \n",
    "        # 提取表格\n",
    "        header = item['table']['header']\n",
    "        rows = item['table']['rows']\n",
    "        \n",
    "        # 创建 DataFrame\n",
    "        df = pd.DataFrame(rows, columns=header)\n",
    "        \n",
    "        # 保存为独立的 CSV 文件 (模拟真实环境)\n",
    "        csv_filename = os.path.join(output_dir, f\"wtq_{i}.csv\")\n",
    "        df.to_csv(csv_filename, index=False)\n",
    "        \n",
    "        # 记录任务信息\n",
    "        tasks.append({\n",
    "            \"id\": item['id'],\n",
    "            \"file\": csv_filename,\n",
    "            \"question\": item['question'],\n",
    "            \"answers\": item['answers'] # 标准答案（用于人工核对）\n",
    "        })\n",
    "    \n",
    "    # 保存任务列表\n",
    "    task_df = pd.DataFrame(tasks)\n",
    "    task_df.to_csv(\"real_benchmark_tasks.csv\", index=False)\n",
    "    \n",
    "    print(f\"✅ 成功！已准备 {sample_size} 个真实表格任务。\")\n",
    "    print(f\"    任务列表保存在: real_benchmark_tasks.csv\")\n",
    "    print(f\"    表格文件保存在: {output_dir}/\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    prepare_wtq_subset(sample_size=20) # 先跑 20 个试试水，没问题了再改成 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
